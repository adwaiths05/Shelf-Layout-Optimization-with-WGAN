{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport random\nimport os\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom typing import List, Tuple\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_LAYOUTS = 10000       # total layouts to generate\nMIN_BOXES = 5\nMAX_BOXES = 20\nNUM_CLASSES = 6           # number of product types\nOUT_PATH = \"layouts.json\"\n\n# Shelf structure parameters\nMIN_ROWS = 2\nMAX_ROWS = 5\nROW_GAP = 0.02            # vertical space between rows\nX_MARGIN = 0.02\nY_MARGIN = 0.02","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_layout():\n    layout = []\n    n_rows = random.randint(MIN_ROWS, MAX_ROWS)\n    total_height = 1.0 - 2 * Y_MARGIN - ROW_GAP * (n_rows - 1)\n    row_height = total_height / n_rows\n\n    y_start = Y_MARGIN\n    for r in range(n_rows):\n        n_boxes = random.randint(MIN_BOXES // n_rows, MAX_BOXES // n_rows)\n        # Random horizontal segmentation\n        x_positions = sorted([random.random() for _ in range(n_boxes - 1)])\n        x_positions = [0.0] + x_positions + [1.0]\n\n        for i in range(n_boxes):\n            x0 = x_positions[i]\n            x1 = x_positions[i + 1]\n            w = max(0.05, (x1 - x0) * random.uniform(0.8, 1.0))\n            cx = X_MARGIN + x0 + w / 2\n            h = row_height * random.uniform(0.8, 1.0)\n            cy = y_start + h / 2\n            cls = random.randint(0, NUM_CLASSES - 1)\n            layout.append([cx, cy, w, h, cls])\n\n        y_start += row_height + ROW_GAP\n\n    return layout","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Config:\ncoco_json = \"data/annotations.json\" # replace path\nimages_dir = \"data/images\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nseed = 42\n\n\n# dataset\nN_max = 32 # pad/truncate boxes per layout\nnum_classes = 50 # set your number of classes\n\n\n# training\nz_dim = 128\nbatch_size = 64\nlr = 1e-4\nbetas = (0.5, 0.9)\nepochs = 200\nn_critic = 5\nlambda_gp = 10.0\nlambda_overlap = 1.0\nsave_every = 10\nout_dir = \"runs/baseline\"\n\n\n# reproducibility\ntorch.manual_seed(Config.seed)\nnp.random.seed(Config.seed)\nrandom.seed(Config.seed)\n\n\nos.makedirs(Config.out_dir, exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def parse_coco_to_layouts(coco_json_path: str, images_dir: str, N_max: int, num_classes: int) -> List[dict]:\n\"\"\"\nParse a COCO-style JSON and return list of layouts.\nEach layout dict: {\n'image_id': ...,\n'boxes': numpy array shape (k,4) in [x,y,w,h] absolute px,\n'labels': list of ints\n'width': image width, 'height': image height\n}\nWe'll convert to normalized [cx, cy, w, h] with values in [0,1]\n\"\"\"\nwith open(coco_json_path, 'r') as f:\ncoco = json.load(f)\n\n\nimgs = {img['id']: img for img in coco['images']}\nanns_by_img = {}\nfor ann in coco['annotations']:\niid = ann['image_id']\nanns_by_img.setdefault(iid, []).append(ann)\n\n\nlayouts = []\nfor iid, img in imgs.items():\nanns = anns_by_img.get(iid, [])\nif len(anns) == 0:\ncontinue\nH, W = img['height'], img['width']\nboxes = []\nlabels = []\nfor a in anns:\nx, y, w, h = a['bbox']\ncx = (x + w/2.0) / W\ncy = (y + h/2.0) / H\nnw = w / W\nnh = h / H\n# clip to [0,1]\ncx = min(max(cx, 0.0), 1.0)\ncy = min(max(cy, 0.0), 1.0)\nnw = min(max(nw, 1e-4), 1.0)\nnh = min(max(nh, 1e-4), 1.0)\nboxes.append([cx, cy, nw, nh])\nlabels.append(min(a.get('category_id', 1)-1, num_classes-1))\n\n\nlayouts.append({'image_id': iid, 'boxes': np.array(boxes, dtype=np.float32),\n'labels': np.array(labels, dtype=np.int64), 'width': W, 'height': H})\nreturn layouts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PlanogramDataset(Dataset):\ndef __init__(self, layouts: List[dict], N_max: int, num_classes: int, shuffle=True):\nself.layouts = layouts\nself.N_max = N_max\nself.num_classes = num_classes\nif shuffle:\nrandom.shuffle(self.layouts)\n\n\ndef __len__(self):\nreturn len(self.layouts)\n\n\ndef __getitem__(self, idx):\nitem = self.layouts[idx]\nboxes = item['boxes'] # (k,4)\nlabels = item['labels'] # (k,)\nk = boxes.shape[0]\nn = min(k, self.N_max)\n\n\n# prepare tensors\ndata = np.zeros((self.N_max, 4 + self.num_classes + 1), dtype=np.float32)\nmask = np.zeros((self.N_max,), dtype=np.float32)\n\n\nfor i in range(n):\ncx, cy, w, h = boxes[i]\ncls = labels[i]\nonehot = np.zeros((self.num_classes,), dtype=np.float32)\nonehot[cls] = 1.0\ndata[i, :4] = [cx, cy, w, h]\ndata[i, 4:4 + self.num_classes] = onehot\ndata[i, -1] = 1.0 # occupancy score\nmask[i] = 1.0\n\n\nreturn torch.from_numpy(data), torch.from_numpy(mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Generator(nn.Module):\ndef __init__(self, z_dim, N_max, num_classes, hidden=512):\nsuper().__init__()\nself.z_dim = z_dim\nself.N_max = N_max\nself.num_classes = num_classes\nout_dim = N_max * (4 + num_classes + 1) # [cx,cy,w,h] + onehot classes + occupancy\n\n\nself.net = nn.Sequential(\nnn.Linear(z_dim, hidden),\nnn.LayerNorm(hidden),\nnn.ReLU(True),\nnn.Linear(hidden, hidden),\nnn.LayerNorm(hidden),\nnn.ReLU(True),\nnn.Linear(hidden, out_dim),\n)\n\n\ndef forward(self, z):\nB = z.shape[0]\nout = self.net(z)\nout = out.view(B, self.N_max, 4 + self.num_classes + 1)\n# boxes coords: apply sigmoid to ensure [0,1]\nout[:, :, :4] = torch.sigmoid(out[:, :, :4])\n# class logits -> softmax across classes\nlogits = out[:, :, 4:4 + self.num_classes]\nprobs = F.softmax(logits, dim=-1)\nout[:, :, 4:4 + self.num_classes] = probs\n# occupancy (last dim) -> sigmoid\nout[:, :, -1] = torch.sigmoid(out[:, :, -1])\nreturn out\n\n\nclass Critic(nn.Module):\ndef __init__(self, N_max, num_classes, hidden=512):\nsuper().__init__()\nin_dim = N_max * (4 + num_classes + 1) + N_max # include mask as extra channel\nself.net = nn.Sequential(\nnn.Linear(in_dim, hidden),\nnn.LeakyReLU(0.2, True),\nnn.Linear(hidden, hidden),\nnn.LeakyReLU(0.2, True),\nnn.Linear(hidden, 1)\n)\n\n\ndef forward(self, x, mask):\n# x: (B, N_max, D); mask: (B, N_max)\nB = x.shape[0]\nflat = x.view(B, -1)\nflat_mask = mask.view(B, -1)\ninp = torch.cat([flat, flat_mask], dim=1)\nreturn self.net(inp).squeeze(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def gradient_penalty(critic, real, fake, mask, device, lambda_gp=10.0):\nB = real.shape[0]\nalpha = torch.rand(B, 1, 1, device=device)\nalpha = alpha.expand_as(real)\ninterpolates = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\ninterpolates_mask = mask # use real mask (approximation)\n\n\nd_interpolates = critic(interpolates, interpolates_mask)\ngrads = torch.autograd.grad(outputs=d_interpolates, inputs=interpolates,\ngrad_outputs=torch.ones_like(d_interpolates, device=device),\ncreate_graph=True, retain_graph=True, only_inputs=True)[0]\ngrads = grads.view(B, -1)\ngp = ((grads.norm(2, dim=1) - 1) ** 2).mean() * lambda_gp\nreturn gp\n\n\n\n\ndef overlap_penalty(boxes_tensor, mask_tensor, iou_threshold=0.05):\n\"\"\"\nSoft penalty: compute pairwise IoU between predicted boxes in a layout and penalize overlap > threshold.\nboxes_tensor: (B, N, 4) with [cx,cy,w,h]\nmask_tensor: (B, N) with occupancy in [0,1]\nreturns scalar tensor\n\"\"\"\nB, N, _ = boxes_tensor.shape\npenalty = 0.0\neps = 1e-6\nfor b in range(B):\nboxes = boxes_tensor[b]\nmask = mask_tensor[b]\nvalid_idx = (mask > 0.5).nonzero(as_tuple=False).squeeze(1)\nm = valid_idx.numel()\nif m <= 1:\ncontinue\nsel = boxes[valid_idx] # (m,4)\n# convert to xyxy\ncx, cy, w, h = sel[:,0], sel[:,1], sel[:,2], sel[:,3]\nx1 = cx - w/2; y1 = cy - h/2\nx2 = cx + w/2; y2 = cy + h/2\n# pairwise IoU\nxx1 = torch.max(x1.unsqueeze(1), x1.unsqueeze(0))\nyy1 = torch.max(y1.unsqueeze(1), y1.unsqueeze(0))\nxx2 = torch.min(x2.unsqueeze(1), x2.unsqueeze(0))\nyy2 = torch.min(y2.unsqueeze(1), y2.unsqueeze(0))\ninter_w = (xx2 - xx1).clamp(min=0)\ninter_h = (yy2 - yy1).clamp(min=0)\ninter = inter_w * inter_h\narea = w * h\nunion = area.unsqueeze(1) + area.unsqueeze(0) - inter + eps\niou = inter / union\n# zero out diagonal\niou = iou - torch.diag(torch.diag(iou))\n# penalize iou > threshold\nover = F.relu(iou - iou_threshold)\npenalty = penalty + over.sum()\n\n\nreturn penalty / (B if B>0 else 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_layout(boxes, mask, title=None, save_path=None):\n# boxes: (N,4) normalized, mask: (N,)\nfig, ax = plt.subplots(1,1, figsize=(6,3))\nax.set_xlim(0,1); ax.set_ylim(1,0)\nax.set_xticks([]); ax.set_yticks([])\nn = boxes.shape[0]\nfor i in range(n):\nif mask[i] < 0.5:\ncontinue\ncx, cy, w, h = boxes[i]\nx = cx - w/2; y = cy - h/2\nrect = plt.Rectangle((x,y), w, h, fill=False, edgecolor='C0')\nax.add_patch(rect)\nif title:\nax.set_title(title)\nif save_path:\nplt.savefig(save_path, bbox_inches='tight')\nplt.close(fig)\nelse:\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train():\nreal_batch = real_batch.to(Config.device) # (B, N, D)\nmask_batch = mask_batch.to(Config.device)\nB = real_batch.shape[0]\n\n\n# -----------------\n# Update critic n_critic times\n# -----------------\nfor _ in range(Config.n_critic):\nz = torch.randn(B, Config.z_dim, device=Config.device)\nfake = G(z).detach()\n\n\nD_real = D(real_batch, mask_batch)\nD_fake = D(fake, mask_batch) # use same mask shape as approximation\n\n\ngp = gradient_penalty(D, real_batch, fake, mask_batch, Config.device, Config.lambda_gp)\nloss_D = D_fake.mean() - D_real.mean() + gp\n\n\noptD.zero_grad()\nloss_D.backward()\noptD.step()\n\n\n# -----------------\n# Update generator\n# -----------------\nz = torch.randn(B, Config.z_dim, device=Config.device)\nfake = G(z)\nD_fake_forG = D(fake, mask_batch)\nloss_G = - D_fake_forG.mean()\n# soft overlap penalty\nboxes_pred = fake[:, :, :4]\nocc = fake[:, :, -1]\noverlap = overlap_penalty(boxes_pred, (occ>0.5).float(), iou_threshold=0.05)\nloss_G = loss_G + Config.lambda_overlap * overlap\n\n\noptG.zero_grad()\nloss_G.backward()\noptG.step()\n\n\niters += 1\n\n\n# end epoch\nprint(f\"Epoch {epoch+1}/{Config.epochs} | loss_D {loss_D.item():.4f} | loss_G {loss_G.item():.4f} | overlap {overlap.item():.4f}\")\n\n\n# sample and save\nif (epoch+1) % Config.save_every == 0 or epoch == 0:\nwith torch.no_grad():\nsamples = G(fixed_z).cpu()\n# visualize first sample in grid\nfor i in range(min(4, samples.shape[0])):\nboxes = samples[i,:, :4].numpy()\nocc = (samples[i,:, -1].numpy() > 0.5).astype(np.float32)\nsave_p = os.path.join(Config.out_dir, f\"epoch{epoch+1}_sample{i}.png\")\nplot_layout(boxes, occ, title=f\"epoch{epoch+1}\", save_path=save_p)\n\n\n# checkpoint\ntorch.save({'G':G.state_dict(), 'D':D.state_dict(), 'optG':optG.state_dict(), 'optD':optD.state_dict()},\nos.path.join(Config.out_dir, f\"ckpt_epoch{epoch+1}.pth\"))\n\n\nprint(\"Training finished\")\n\n\nif __name__ == '__main__':\ntrain()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}