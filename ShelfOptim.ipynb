{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport random\nimport os\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom typing import List, Tuple\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:55.827499Z","iopub.execute_input":"2025-11-04T09:56:55.828423Z","iopub.status.idle":"2025-11-04T09:56:55.832955Z","shell.execute_reply.started":"2025-11-04T09:56:55.828389Z","shell.execute_reply":"2025-11-04T09:56:55.832153Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"NUM_LAYOUTS = 10000       # total layouts to generate\nMIN_BOXES = 5\nMAX_BOXES = 20\nNUM_CLASSES = 6           # number of product types\nOUT_PATH = \"/kaggle/working/layouts.json\"\n\n# Shelf structure parameters\nMIN_ROWS = 2\nMAX_ROWS = 5\nROW_GAP = 0.02            # vertical space between rows\nX_MARGIN = 0.02\nY_MARGIN = 0.02","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:55.834170Z","iopub.execute_input":"2025-11-04T09:56:55.834409Z","iopub.status.idle":"2025-11-04T09:56:55.848644Z","shell.execute_reply.started":"2025-11-04T09:56:55.834389Z","shell.execute_reply":"2025-11-04T09:56:55.848032Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def generate_layout():\n    layout = []\n    n_rows = random.randint(MIN_ROWS, MAX_ROWS)\n    total_height = 1.0 - 2 * Y_MARGIN - ROW_GAP * (n_rows - 1)\n    row_height = total_height / n_rows\n\n    y_start = Y_MARGIN\n    for r in range(n_rows):\n        n_boxes = random.randint(MIN_BOXES // n_rows, MAX_BOXES // n_rows)\n        # Random horizontal segmentation\n        x_positions = sorted([random.random() for _ in range(n_boxes - 1)])\n        x_positions = [0.0] + x_positions + [1.0]\n\n        for i in range(n_boxes):\n            x0 = x_positions[i]\n            x1 = x_positions[i + 1]\n            w = max(0.05, (x1 - x0) * random.uniform(0.8, 1.0))\n            cx = X_MARGIN + x0 + w / 2\n            h = row_height * random.uniform(0.8, 1.0)\n            cy = y_start + h / 2\n            cls = random.randint(0, NUM_CLASSES - 1)\n            layout.append([cx, cy, w, h, cls])\n\n        y_start += row_height + ROW_GAP\n\n    return layout","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:55.849237Z","iopub.execute_input":"2025-11-04T09:56:55.849439Z","iopub.status.idle":"2025-11-04T09:56:55.862430Z","shell.execute_reply.started":"2025-11-04T09:56:55.849425Z","shell.execute_reply":"2025-11-04T09:56:55.861735Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    layouts = []\n    for _ in tqdm(range(NUM_LAYOUTS), desc=\"Generating layouts\"):\n        layouts.append(generate_layout())\n\n    os.makedirs(os.path.dirname(OUT_PATH) or \".\", exist_ok=True)\n    with open(OUT_PATH, \"w\") as f:\n        json.dump(layouts, f)\n\n    print(f\"\\n✅ Generated {NUM_LAYOUTS} synthetic layouts and saved to '{OUT_PATH}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:55.863769Z","iopub.execute_input":"2025-11-04T09:56:55.863957Z","iopub.status.idle":"2025-11-04T09:56:56.850756Z","shell.execute_reply.started":"2025-11-04T09:56:55.863943Z","shell.execute_reply":"2025-11-04T09:56:56.849938Z"}},"outputs":[{"name":"stderr","text":"Generating layouts: 100%|██████████| 10000/10000 [00:00<00:00, 33952.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✅ Generated 10000 synthetic layouts and saved to '/kaggle/working/layouts.json'\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport numpy as np\nimport json\n\nclass PlanogramDataset(Dataset):\n    def __init__(self, json_path, N_max=32, num_classes=6):\n        self.N_max = N_max\n        self.num_classes = num_classes\n        with open(json_path, 'r') as f:\n            self.layouts = json.load(f)\n\n    def __len__(self):\n        return len(self.layouts)\n\n    def __getitem__(self, idx):\n        layout = self.layouts[idx]\n        k = len(layout)\n        n = min(k, self.N_max)\n        data = np.zeros((self.N_max, 4 + self.num_classes + 1), dtype=np.float32)\n        mask = np.zeros((self.N_max,), dtype=np.float32)\n\n        for i in range(n):\n            cx, cy, w, h, cls = layout[i]\n            onehot = np.zeros((self.num_classes,), dtype=np.float32)\n            onehot[int(cls)] = 1.0\n            data[i, :4] = [cx, cy, w, h]\n            data[i, 4:4+self.num_classes] = onehot\n            data[i, -1] = 1.0\n            mask[i] = 1.0\n\n        return torch.from_numpy(data), torch.from_numpy(mask)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:56.851519Z","iopub.execute_input":"2025-11-04T09:56:56.851815Z","iopub.status.idle":"2025-11-04T09:56:56.858813Z","shell.execute_reply.started":"2025-11-04T09:56:56.851797Z","shell.execute_reply":"2025-11-04T09:56:56.858022Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Critic(nn.Module):\n    def __init__(self, N_max=32, num_classes=6, hidden=512):\n        super().__init__()\n        in_dim = N_max * (4 + num_classes + 1) + N_max  # include mask\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden),\n            nn.LeakyReLU(0.2, True),\n            nn.Linear(hidden, hidden),\n            nn.LeakyReLU(0.2, True),\n            nn.Linear(hidden, 1)\n        )\n\n    def forward(self, x, mask):\n        B = x.shape[0]\n        flat = x.view(B, -1)\n        flat_mask = mask.view(B, -1)\n        inp = torch.cat([flat, flat_mask], dim=1)\n        return self.net(inp).squeeze(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:56.859506Z","iopub.execute_input":"2025-11-04T09:56:56.859714Z","iopub.status.idle":"2025-11-04T09:56:56.877026Z","shell.execute_reply.started":"2025-11-04T09:56:56.859699Z","shell.execute_reply":"2025-11-04T09:56:56.876338Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\ndef gradient_penalty(critic, real, fake, mask, device, lambda_gp=10.0):\n    B = real.shape[0]\n    alpha = torch.rand(B, 1, 1, device=device).expand_as(real)\n    interpolates = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n    d_interpolates = critic(interpolates, mask)\n    grads = torch.autograd.grad(\n        outputs=d_interpolates, inputs=interpolates,\n        grad_outputs=torch.ones_like(d_interpolates),\n        create_graph=True, retain_graph=True, only_inputs=True\n    )[0]\n    grads = grads.view(B, -1)\n    gp = ((grads.norm(2, dim=1) - 1)**2).mean() * lambda_gp\n    return gp\n\ndef overlap_penalty(boxes_tensor, mask_tensor, iou_threshold=0.05):\n    B, N, _ = boxes_tensor.shape\n    penalty = 0.0\n    eps = 1e-6\n    for b in range(B):\n        boxes = boxes_tensor[b]\n        mask = mask_tensor[b]\n        valid_idx = (mask > 0.5).nonzero(as_tuple=False).squeeze(1)\n        m = valid_idx.numel()\n        if m <= 1: continue\n        sel = boxes[valid_idx]\n        cx, cy, w, h = sel[:,0], sel[:,1], sel[:,2], sel[:,3]\n        x1 = cx - w/2; y1 = cy - h/2; x2 = cx + w/2; y2 = cy + h/2\n        xx1 = torch.max(x1.unsqueeze(1), x1.unsqueeze(0))\n        yy1 = torch.max(y1.unsqueeze(1), y1.unsqueeze(0))\n        xx2 = torch.min(x2.unsqueeze(1), x2.unsqueeze(0))\n        yy2 = torch.min(y2.unsqueeze(1), y2.unsqueeze(0))\n        inter = (xx2 - xx1).clamp(min=0) * (yy2 - yy1).clamp(min=0)\n        area = w * h\n        union = area.unsqueeze(1) + area.unsqueeze(0) - inter + eps\n        iou = inter / union\n        iou = iou - torch.diag(torch.diag(iou))\n        penalty += F.relu(iou - iou_threshold).sum()\n    return penalty / max(B,1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:56.877826Z","iopub.execute_input":"2025-11-04T09:56:56.878128Z","iopub.status.idle":"2025-11-04T09:56:56.890797Z","shell.execute_reply.started":"2025-11-04T09:56:56.878107Z","shell.execute_reply":"2025-11-04T09:56:56.890223Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_layout(boxes, mask, title=None, save_path=None):\n    fig, ax = plt.subplots(1,1, figsize=(6,3))\n    ax.set_xlim(0,1); ax.set_ylim(1,0); ax.set_xticks([]); ax.set_yticks([])\n    n = boxes.shape[0]\n    for i in range(n):\n        if mask[i] < 0.5: continue\n        cx, cy, w, h = boxes[i]\n        rect = plt.Rectangle((cx-w/2, cy-h/2), w, h, fill=False, edgecolor='C0')\n        ax.add_patch(rect)\n    if title: ax.set_title(title)\n    if save_path:\n        plt.savefig(save_path, bbox_inches='tight'); plt.close(fig)\n    else:\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:56.892500Z","iopub.execute_input":"2025-11-04T09:56:56.892960Z","iopub.status.idle":"2025-11-04T09:56:56.906082Z","shell.execute_reply.started":"2025-11-04T09:56:56.892937Z","shell.execute_reply":"2025-11-04T09:56:56.905479Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import DataLoader\nfrom dataset import PlanogramDataset\nfrom model_generator import Generator\nfrom model_critic import Critic\nfrom losses import gradient_penalty, overlap_penalty\nfrom visualize import plot_layout\nimport json\n\ndef train():\n    # -------------------------\n    # Load synthetic layouts\n    # -------------------------\n    with open(\"layouts.json\", \"r\") as f:\n        layouts = json.load(f)\n\n    ds = PlanogramDataset(layouts, N_max=32, num_classes=6)\n    dl = DataLoader(ds, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n\n    # -------------------------\n    # Initialize models and optimizers\n    # -------------------------\n    G = Generator(z_dim=128, N_max=32, num_classes=6).to(\"cuda\")\n    D = Critic(N_max=32, num_classes=6).to(\"cuda\")\n\n    optG = torch.optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.9))\n    optD = torch.optim.Adam(D.parameters(), lr=1e-4, betas=(0.5, 0.9))\n\n    fixed_z = torch.randn(16, 128, device=\"cuda\")  # fixed noise for visualization\n\n    # -------------------------\n    # Training loop\n    # -------------------------\n    for epoch in range(10):  # set number of epochs\n        for real_batch, mask_batch in dl:\n            real_batch = real_batch.to(\"cuda\")\n            mask_batch = mask_batch.to(\"cuda\")\n            B = real_batch.shape[0]\n\n            # --------- Update critic ---------\n            for _ in range(5):  # n_critic\n                z = torch.randn(B, 128, device=\"cuda\")\n                fake = G(z).detach()\n                D_real = D(real_batch, mask_batch)\n                D_fake = D(fake, mask_batch)\n                gp = gradient_penalty(D, real_batch, fake, mask_batch, device=\"cuda\")\n                loss_D = D_fake.mean() - D_real.mean() + gp\n\n                optD.zero_grad()\n                loss_D.backward()\n                optD.step()\n\n            # --------- Update generator ---------\n            z = torch.randn(B, 128, device=\"cuda\")\n            fake = G(z)\n            D_fake_forG = D(fake, mask_batch)\n            loss_G = -D_fake_forG.mean()\n\n            boxes_pred = fake[:, :, :4]\n            occ = fake[:, :, -1]\n            overlap = overlap_penalty(boxes_pred, (occ > 0.5).float())\n            loss_G += 10.0 * overlap  # lambda_overlap = 10\n\n            optG.zero_grad()\n            loss_G.backward()\n            optG.step()\n\n        # --------- End epoch: print and save sample ---------\n        print(f\"Epoch {epoch+1}/10 | loss_D {loss_D.item():.4f} | \"\n              f\"loss_G {loss_G.item():.4f} | overlap {overlap.item():.4f}\")\n\n        # visualize a few samples\n        with torch.no_grad():\n            samples = G(fixed_z).cpu()\n        for i in range(min(4, samples.shape[0])):\n            boxes = samples[i, :, :4].numpy()\n            occ_mask = (samples[i, :, -1].numpy() > 0.5).astype(float)\n            os.makedirs(\"samples\", exist_ok=True)\n            save_path = f\"samples/epoch{epoch+1}_sample{i}.png\"\n            plot_layout(boxes, occ_mask, title=f\"epoch {epoch+1}\", save_path=save_path)\n\n    print(\"Training finished\")\n\n\nif __name__ == \"__main__\":\n    train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T09:56:56.906849Z","iopub.execute_input":"2025-11-04T09:56:56.907135Z","iopub.status.idle":"2025-11-04T09:56:57.024086Z","shell.execute_reply.started":"2025-11-04T09:56:56.907116Z","shell.execute_reply":"2025-11-04T09:56:57.023092Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2869737312.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlanogramDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_critic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCritic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'"],"ename":"ModuleNotFoundError","evalue":"No module named 'dataset'","output_type":"error"}],"execution_count":29}]}